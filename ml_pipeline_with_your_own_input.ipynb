{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1817d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbd61d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = chain(nltk.corpus.stopwords.words(\"english\"), \n",
    "                  nltk.corpus.stopwords.words(\"portuguese\"))\n",
    "MAX_FEATURES = [50, None, 500, 10000]\n",
    "SOLVERS = ['lbfgs','liblinear','newton-cg','sag','saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a26f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_words(*args):\n",
    "    for arg in args:\n",
    "        STOP_WORDS.append(arg)\n",
    "    return STOP_WORDS\n",
    "def normalize_sentence(sentence):\n",
    "    norm_sentence = sentence.lower()\n",
    "    norm_sentence = re.sub(r'[^\\w\\s]','', norm_sentence) \n",
    "    norm_sentence = norm_sentence.strip() \n",
    "    norm_sentence = unidecode(norm_sentence)\n",
    "    norm_sentence = ' '.join(norm_sentence.split()) \n",
    "    return norm_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec541aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xinput = ['terceira guerra mundial vem se aproximando', 'data science é muito útil para lidar com dados', 'agora o elon musk comprou o twitter', 'manhã com chuva', 'as acoes da bolsa subiram muito', 'bitcoin baixou', 'voce vai viajar?']\n",
    "yinput = [-1, 0, 1, 0, 1, -1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f49ce5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 165.73it/s]\n"
     ]
    }
   ],
   "source": [
    "white_space_tokenize = tokenize.WhitespaceTokenizer()  \n",
    "phrase_pos = list()\n",
    "for text in tqdm(xinput):\n",
    "    new_phrase = list()\n",
    "    phrase_text = white_space_tokenize.tokenize(\n",
    "        text #normalize_sentence(text)\n",
    "    )\n",
    "    for word in phrase_text:\n",
    "        if word not in STOP_WORDS:\n",
    "            stemmer = nltk.RSLPStemmer()\n",
    "            norm_word = stemmer.stem(word)\n",
    "            new_phrase.append(norm_word)\n",
    "\n",
    "    phrase_pos.append(' '.join(new_phrase))\n",
    "xinput_pos = phrase_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46507bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1,  0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features=500)\n",
    "bag_of_words = vectorizer.fit_transform(xinput_pos)\n",
    "train, test, class_train, class_test =\\\n",
    "        train_test_split(bag_of_words, yinput, test_size=0.2, random_state=4)\n",
    "logistic_regression = LogisticRegression(solver='newton-cg')\n",
    "logistic_regression.fit(train, class_train)\n",
    "logistic_regression.predict(bag_of_words)\n",
    "#logistic_regression.score(bag_of_words, yinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42d6f8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.score(bag_of_words,yinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d60a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  0 -1 -1 -1]\n",
      "0.7142857142857143\n",
      "[-1  0  1  0  0 -1 -1]\n",
      "0.7142857142857143\n",
      "[-1  0  1  0 -1 -1 -1]\n",
      "0.7142857142857143\n",
      "[-1  0  1  0  0 -1 -1]\n",
      "0.7142857142857143\n",
      "[-1  0  1  0  0 -1 -1]\n",
      "0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marten/Desktop/workdir/ALURA/NLP/venv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def test_solvers(solver):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bag_of_words = vectorizer.fit_transform(xinput_pos)\n",
    "    train, test, class_train, class_test =\\\n",
    "            train_test_split(bag_of_words, yinput, test_size=0.2, random_state=4)\n",
    "    logistic_regression = LogisticRegression(solver=solver)\n",
    "    logistic_regression.fit(train, class_train)\n",
    "    print(logistic_regression.predict(bag_of_words))\n",
    "    print(logistic_regression.score(bag_of_words,yinput))\n",
    "for solver in SOLVERS:\n",
    "    test_solvers(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02de2a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1, 0, 1, -1, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d182e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5e601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad476649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd240e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef6995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622c5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
